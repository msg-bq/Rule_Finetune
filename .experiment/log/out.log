2024-02-04 17:53:49,616 - C:/Users/lbq/Documents/GitHub/Rule_Finetune/main.py[line:85] - INFO: args: Namespace(cot_trigger='Answer: Let\'s think step by step. First rationale then answer.If you use any prior knowledge or rule during the inference, write them briefly in "<Begin>xxx</End>" format. Only do this if you find them. Note that these rules should be true in general.', cot_trigger_type='default1', data_dir=None, dataset='CLUTRR', debug=True, demo_save_dir='demosave', direct_answer_trigger_for_zeroshot_cot='The answer is', encoder='all-MiniLM-L6-v2', epoch=10, eval=False, llm_model='gpt-3.5-turbo-1106', llm_model_path=None, multi_thread=True, num_clusters=5, pred_trigger='The answer is', random_seed=192, rationale_dir=None, save_dir='./experiment', test=False, topN=1, train=True)
2024-02-04 17:54:14,649 - C:/Users/lbq/Documents/GitHub/Rule_Finetune/main.py[line:85] - INFO: args: Namespace(cot_trigger='Answer: Let\'s think step by step. First rationale then answer.If you use any prior knowledge or rule during the inference, write them briefly in "<Begin>xxx</End>" format. Only do this if you find them. Note that these rules should be true in general.', cot_trigger_type='default1', data_dir=None, dataset='CLUTRR', debug=True, demo_save_dir='demosave', direct_answer_trigger_for_zeroshot_cot='The answer is', encoder='all-MiniLM-L6-v2', epoch=10, eval=False, llm_model='gpt-3.5-turbo-1106', llm_model_path=None, multi_thread=True, num_clusters=5, pred_trigger='The answer is', random_seed=192, rationale_dir=None, save_dir='./experiment', test=False, topN=1, train=True)
2024-02-04 17:54:14,685 - C:\Users\lbq\Documents\GitHub\Rule_Finetune\RuleFinetune\RuleTrainer.py[line:42] - INFO: 完成cold start
2024-02-04 17:55:37,250 - C:\Users\lbq\Documents\GitHub\Rule_Finetune\RuleFinetune\RuleTrainer.py[line:158] - INFO: epoch0的平均score为：0.6024444231891043
2024-02-04 17:57:24,188 - C:\Users\lbq\Documents\GitHub\Rule_Finetune\RuleFinetune\RuleTrainer.py[line:158] - INFO: epoch1的平均score为：0.6945238365970077
2024-02-04 17:59:07,669 - C:\Users\lbq\Documents\GitHub\Rule_Finetune\RuleFinetune\RuleTrainer.py[line:158] - INFO: epoch2的平均score为：0.7159410862769072
2024-02-04 18:00:41,819 - C:\Users\lbq\Documents\GitHub\Rule_Finetune\RuleFinetune\RuleTrainer.py[line:158] - INFO: epoch3的平均score为：0.7028720579140747
2024-02-04 18:02:13,104 - C:\Users\lbq\Documents\GitHub\Rule_Finetune\RuleFinetune\RuleTrainer.py[line:158] - INFO: epoch4的平均score为：0.670568680428306
2024-02-04 18:03:32,816 - C:\Users\lbq\Documents\GitHub\Rule_Finetune\RuleFinetune\RuleTrainer.py[line:158] - INFO: epoch5的平均score为：0.6984947312660295
2024-02-04 18:04:56,784 - C:\Users\lbq\Documents\GitHub\Rule_Finetune\RuleFinetune\RuleTrainer.py[line:158] - INFO: epoch6的平均score为：0.7193168159965037
2024-02-04 18:06:27,635 - C:\Users\lbq\Documents\GitHub\Rule_Finetune\RuleFinetune\RuleTrainer.py[line:158] - INFO: epoch7的平均score为：0.6443710661571195
2024-02-04 18:08:31,121 - C:\Users\lbq\Documents\GitHub\Rule_Finetune\RuleFinetune\RuleTrainer.py[line:158] - INFO: epoch8的平均score为：0.6979898356851482
2024-02-04 18:10:08,501 - C:\Users\lbq\Documents\GitHub\Rule_Finetune\RuleFinetune\RuleTrainer.py[line:158] - INFO: epoch9的平均score为：0.7012010954924341
2024-02-05 10:50:22,064 - C:/Users/lbq/Documents/GitHub/Rule_Finetune/main.py[line:85] - INFO: args: Namespace(cot_trigger='Answer: Let\'s think step by step. First rationale then answer.If you use any prior knowledge or rule during the inference, write them briefly in "<Begin>xxx</End>" format. Only do this if you find them. Note that these rules should be true in general.', cot_trigger_type='default1', data_dir=None, dataset='CLUTRR', debug=True, demo_save_dir='demosave', direct_answer_trigger_for_zeroshot_cot='The answer is', encoder='all-MiniLM-L6-v2', epoch=3, eval=False, llm_model='gpt-3.5-turbo-1106', llm_model_path=None, multi_thread=True, num_clusters=5, pred_trigger='The answer is', random_seed=192, rationale_dir=None, save_dir='./experiment', test=False, topN=1, train=True)
2024-02-05 10:50:22,097 - C:\Users\lbq\Documents\GitHub\Rule_Finetune\RuleFinetune\RuleTrainer.py[line:42] - INFO: 完成cold start
2024-02-05 11:34:14,877 - C:/Users/lbq/Documents/GitHub/Rule_Finetune/main.py[line:85] - INFO: args: Namespace(cot_trigger='Answer: Let\'s think step by step. First rationale then answer.If you use any prior knowledge or rule during the inference, write them briefly in "<Begin>xxx</End>" format. Only do this if you find them. Note that these rules should be true in general.', cot_trigger_type='default1', data_dir=None, dataset='CLUTRR', debug=True, demo_save_dir='demosave', direct_answer_trigger_for_zeroshot_cot='The answer is', encoder='all-MiniLM-L6-v2', epoch=3, eval=False, llm_model='gpt-3.5-turbo-1106', llm_model_path=None, multi_thread=True, num_clusters=5, pred_trigger='The answer is', random_seed=192, rationale_dir=None, save_dir='./experiment', test=False, topN=1, train=True)
2024-02-05 11:34:14,892 - C:\Users\lbq\Documents\GitHub\Rule_Finetune\RuleFinetune\RuleTrainer.py[line:42] - INFO: 完成cold start
2024-02-05 11:35:27,035 - C:\Users\lbq\Documents\GitHub\Rule_Finetune\RuleFinetune\RuleTrainer.py[line:158] - INFO: epoch0的平均score为：0.6126724466010182
2024-02-05 11:36:33,974 - C:\Users\lbq\Documents\GitHub\Rule_Finetune\RuleFinetune\RuleTrainer.py[line:158] - INFO: epoch1的平均score为：0.651042533855034
2024-02-05 11:37:43,390 - C:\Users\lbq\Documents\GitHub\Rule_Finetune\RuleFinetune\RuleTrainer.py[line:158] - INFO: epoch2的平均score为：0.7431265476378259
2024-02-05 11:46:10,576 - C:/Users/lbq/Documents/GitHub/Rule_Finetune/main.py[line:86] - INFO: args: Namespace(cot_trigger='Answer: Let\'s think step by step. First rationale then answer.If you use any prior knowledge or rule during the inference, write them briefly in "<Begin>xxx</End>" format. Only do this if you find them. Note that these rules should be true in general.', cot_trigger_type='default1', data_dir=None, dataset='CLUTRR', debug=True, demo_save_dir='demosave', direct_answer_trigger_for_zeroshot_cot='The answer is', encoder='all-MiniLM-L6-v2', epoch=3, eval=False, llm_model='gpt-3.5-turbo-1106', llm_model_path=None, multi_thread=True, num_clusters=5, pred_trigger='The answer is', random_seed=192, rationale_dir=None, save_dir='./experiment', test=False, topN=1, train=True)
2024-02-05 11:46:15,613 - C:\Users\lbq\Documents\GitHub\Rule_Finetune\RuleFinetune\RuleTrainer.py[line:42] - INFO: 完成cold start
2024-02-05 11:48:34,124 - C:\Users\lbq\Documents\GitHub\Rule_Finetune\RuleFinetune\RuleTrainer.py[line:158] - INFO: epoch0的平均score为：0.6435753532182108
2024-02-05 11:51:20,764 - C:/Users/lbq/Documents/GitHub/Rule_Finetune/main.py[line:86] - INFO: args: Namespace(cot_trigger='Answer: Let\'s think step by step. First rationale then answer.If you use any prior knowledge or rule during the inference, write them briefly in "<Begin>xxx</End>" format. Only do this if you find them. Note that these rules should be true in general.', cot_trigger_type='default1', data_dir=None, dataset='CLUTRR', debug=True, demo_save_dir='demosave', direct_answer_trigger_for_zeroshot_cot='The answer is', encoder='all-MiniLM-L6-v2', epoch=3, eval=False, llm_model='gpt-3.5-turbo-1106', llm_model_path=None, multi_thread=True, num_clusters=5, pred_trigger='The answer is', random_seed=192, rationale_dir=None, save_dir='./experiment', test=False, topN=1, train=True)
2024-02-05 11:51:27,860 - C:\Users\lbq\Documents\GitHub\Rule_Finetune\RuleFinetune\RuleTrainer.py[line:42] - INFO: 完成cold start
2024-02-05 11:52:29,687 - C:\Users\lbq\Documents\GitHub\Rule_Finetune\RuleFinetune\RuleTrainer.py[line:158] - INFO: epoch0的平均score为：0.6381344845630561
2024-02-05 12:06:07,356 - C:/Users/lbq/Documents/GitHub/Rule_Finetune/main.py[line:86] - INFO: args: Namespace(cot_trigger='Answer: Let\'s think step by step. First rationale then answer.If you use any prior knowledge or rule during the inference, write them briefly in "<Begin>xxx</End>" format. Only do this if you find them. Note that these rules should be true in general.', cot_trigger_type='default1', data_dir=None, dataset='CLUTRR', debug=True, demo_save_dir='demosave', direct_answer_trigger_for_zeroshot_cot='The answer is', encoder='all-MiniLM-L6-v2', epoch=3, eval=False, llm_model='gpt-3.5-turbo-1106', llm_model_path=None, multi_thread=True, num_clusters=5, pred_trigger='The answer is', random_seed=192, rationale_dir=None, save_dir='./experiment', test=False, topN=1, train=True)
2024-02-05 12:06:13,849 - C:\Users\lbq\Documents\GitHub\Rule_Finetune\RuleFinetune\RuleTrainer.py[line:42] - INFO: 完成cold start
2024-02-05 12:09:44,742 - C:\Users\lbq\Documents\GitHub\Rule_Finetune\RuleFinetune\RuleTrainer.py[line:158] - INFO: epoch0的平均score为：0.6391302550877023
2024-02-05 12:10:35,219 - C:\Users\lbq\Documents\GitHub\Rule_Finetune\RuleFinetune\RuleTrainer.py[line:158] - INFO: epoch1的平均score为：0.6121817696787099
2024-02-05 12:11:28,611 - C:\Users\lbq\Documents\GitHub\Rule_Finetune\RuleFinetune\RuleTrainer.py[line:158] - INFO: epoch2的平均score为：0.6386053886053891
2024-02-05 12:17:41,919 - C:/Users/lbq/Documents/GitHub/Rule_Finetune/main.py[line:86] - INFO: args: Namespace(cot_trigger='Answer: Let\'s think step by step. First rationale then answer.If you use any prior knowledge or rule during the inference, write them briefly in "<Begin>xxx</End>" format. Only do this if you find them. Note that these rules should be true in general.', cot_trigger_type='default1', data_dir=None, dataset='CLUTRR', debug=True, demo_save_dir='demosave', direct_answer_trigger_for_zeroshot_cot='The answer is', encoder='all-MiniLM-L6-v2', epoch=3, eval=False, llm_model='gpt-3.5-turbo-1106', llm_model_path=None, multi_thread=True, num_clusters=5, pred_trigger='The answer is', random_seed=192, rationale_dir=None, save_dir='./experiment', test=False, topN=1, train=True)
2024-02-05 12:17:51,120 - C:\Users\lbq\Documents\GitHub\Rule_Finetune\RuleFinetune\RuleTrainer.py[line:42] - INFO: 完成cold start
2024-02-05 12:19:08,482 - C:\Users\lbq\Documents\GitHub\Rule_Finetune\RuleFinetune\RuleTrainer.py[line:158] - INFO: epoch0的平均score为：0.6342472418292093
2024-02-05 12:22:48,175 - C:\Users\lbq\Documents\GitHub\Rule_Finetune\RuleFinetune\RuleTrainer.py[line:158] - INFO: epoch1的平均score为：0.6938679489908998
2024-02-05 12:23:47,384 - C:\Users\lbq\Documents\GitHub\Rule_Finetune\RuleFinetune\RuleTrainer.py[line:158] - INFO: epoch2的平均score为：0.6447583477128933
2024-02-05 12:29:21,477 - C:/Users/lbq/Documents/GitHub/Rule_Finetune/main.py[line:86] - INFO: args: Namespace(cot_trigger='Answer: Let\'s think step by step. First rationale then answer.If you use any prior knowledge or rule during the inference, write them briefly in "<Begin>xxx</End>" format. Only do this if you find them. Note that these rules should be true in general.', cot_trigger_type='default1', data_dir=None, dataset='CLUTRR', debug=True, demo_save_dir='demosave', direct_answer_trigger_for_zeroshot_cot='The answer is', encoder='all-MiniLM-L6-v2', epoch=5, eval=False, llm_model='gpt-3.5-turbo-1106', llm_model_path=None, multi_thread=True, num_clusters=5, pred_trigger='The answer is', random_seed=192, rationale_dir=None, save_dir='./experiment', test=False, topN=1, train=True)
2024-02-05 12:29:25,895 - C:\Users\lbq\Documents\GitHub\Rule_Finetune\RuleFinetune\RuleTrainer.py[line:42] - INFO: 完成cold start
2024-02-05 12:30:32,991 - C:\Users\lbq\Documents\GitHub\Rule_Finetune\RuleFinetune\RuleTrainer.py[line:158] - INFO: epoch0的平均score为：0.6561053013180675
2024-02-05 12:31:29,790 - C:\Users\lbq\Documents\GitHub\Rule_Finetune\RuleFinetune\RuleTrainer.py[line:158] - INFO: epoch1的平均score为：0.6510963591116266
2024-02-05 12:32:26,808 - C:\Users\lbq\Documents\GitHub\Rule_Finetune\RuleFinetune\RuleTrainer.py[line:158] - INFO: epoch2的平均score为：0.6919795890384125
2024-02-05 12:33:29,810 - C:\Users\lbq\Documents\GitHub\Rule_Finetune\RuleFinetune\RuleTrainer.py[line:158] - INFO: epoch3的平均score为：0.6912191818206856
2024-02-05 12:34:32,102 - C:\Users\lbq\Documents\GitHub\Rule_Finetune\RuleFinetune\RuleTrainer.py[line:158] - INFO: epoch4的平均score为：0.688155681853161
2024-02-05 12:46:34,877 - C:/Users/lbq/Documents/GitHub/Rule_Finetune/main.py[line:86] - INFO: args: Namespace(cot_trigger='Answer: Let\'s think step by step. First rationale then answer.If you use any prior knowledge or rule during the inference, write them briefly in "<Begin>xxx</End>" format. Only do this if you find them. Note that these rules should be true in general.', cot_trigger_type='default1', data_dir=None, dataset='CLUTRR', debug=True, demo_save_dir='demosave', direct_answer_trigger_for_zeroshot_cot='The answer is', encoder='all-MiniLM-L6-v2', epoch=5, eval=False, llm_model='gpt-3.5-turbo-1106', llm_model_path=None, multi_thread=True, num_clusters=5, pred_trigger='The answer is', random_seed=192, rationale_dir=None, save_dir='./experiment', test=False, topN=1, train=True)
2024-02-05 12:46:40,265 - C:\Users\lbq\Documents\GitHub\Rule_Finetune\RuleFinetune\RuleTrainer.py[line:42] - INFO: 完成cold start
2024-02-05 12:47:49,927 - C:\Users\lbq\Documents\GitHub\Rule_Finetune\RuleFinetune\RuleTrainer.py[line:158] - INFO: epoch0的平均score为：0.6103706245792576
2024-02-05 12:48:57,969 - C:\Users\lbq\Documents\GitHub\Rule_Finetune\RuleFinetune\RuleTrainer.py[line:158] - INFO: epoch1的平均score为：0.6719201224840323
2024-02-05 12:49:52,436 - C:\Users\lbq\Documents\GitHub\Rule_Finetune\RuleFinetune\RuleTrainer.py[line:158] - INFO: epoch2的平均score为：0.6644764186430856
2024-02-05 12:50:51,396 - C:\Users\lbq\Documents\GitHub\Rule_Finetune\RuleFinetune\RuleTrainer.py[line:158] - INFO: epoch3的平均score为：0.6958544842691187
2024-02-05 12:51:49,787 - C:\Users\lbq\Documents\GitHub\Rule_Finetune\RuleFinetune\RuleTrainer.py[line:158] - INFO: epoch4的平均score为：0.6514157454553087
2024-02-05 14:57:29,938 - C:/Users/lbq/Documents/GitHub/Rule_Finetune/main.py[line:86] - INFO: args: Namespace(cot_trigger='Answer: Let\'s think step by step. First rationale then answer.If you use any prior knowledge or rule during the inference, write them briefly in "<Begin>xxx</End>" format. Only do this if you find them. Note that these rules should be true in general.', cot_trigger_type='default1', data_dir=None, dataset='CLUTRR', debug=True, demo_save_dir='demosave', direct_answer_trigger_for_zeroshot_cot='The answer is', encoder='all-MiniLM-L6-v2', epoch=5, eval=False, llm_model='gpt-3.5-turbo-1106', llm_model_path=None, multi_thread=True, num_clusters=5, pred_trigger='The answer is', random_seed=192, rationale_dir=None, save_dir='./experiment', test=False, topN=1, train=True)
2024-02-05 14:59:51,995 - C:/Users/lbq/Documents/GitHub/Rule_Finetune/main.py[line:86] - INFO: args: Namespace(cot_trigger='Answer: Let\'s think step by step. First rationale then answer.If you use any prior knowledge or rule during the inference, write them briefly in "<Begin>xxx</End>" format. Only do this if you find them. Note that these rules should be true in general.', cot_trigger_type='default1', data_dir=None, dataset='CLUTRR', debug=True, demo_save_dir='demosave', direct_answer_trigger_for_zeroshot_cot='The answer is', encoder='all-MiniLM-L6-v2', epoch=5, eval=False, llm_model='gpt-3.5-turbo-1106', llm_model_path=None, multi_thread=True, num_clusters=5, pred_trigger='The answer is', random_seed=192, rationale_dir=None, save_dir='./experiment', test=False, topN=1, train=True)
2024-02-05 15:03:56,497 - C:\Users\lbq\Documents\GitHub\Rule_Finetune\RuleFinetune\RuleTrainer.py[line:42] - INFO: 完成cold start
2024-02-05 15:13:28,279 - C:/Users/lbq/Documents/GitHub/Rule_Finetune/main.py[line:86] - INFO: args: Namespace(cot_trigger='Answer: Let\'s think step by step. First rationale then answer.If you use any prior knowledge or rule during the inference, write them briefly in "<Begin>xxx</End>" format. Only do this if you find them. Note that these rules should be true in general.', cot_trigger_type='default1', data_dir=None, dataset='CLUTRR', debug=True, demo_save_dir='demosave', direct_answer_trigger_for_zeroshot_cot='The answer is', encoder='all-MiniLM-L6-v2', epoch=5, eval=False, llm_model='gpt-3.5-turbo-1106', llm_model_path=None, multi_thread=True, num_clusters=5, pred_trigger='The answer is', random_seed=192, rationale_dir=None, save_dir='./experiment', test=False, topN=1, train=True)
2024-02-05 15:33:25,337 - C:/Users/lbq/Documents/GitHub/Rule_Finetune/main.py[line:86] - INFO: args: Namespace(cot_trigger='Answer: Let\'s think step by step. First rationale then answer.If you use any prior knowledge or rule during the inference, write them briefly in "<Begin>xxx</End>" format. Only do this if you find them. Note that these rules should be true in general.', cot_trigger_type='default1', data_dir=None, dataset='CLUTRR', debug=True, demo_save_dir='demosave', direct_answer_trigger_for_zeroshot_cot='The answer is', encoder='all-MiniLM-L6-v2', epoch=5, eval=False, llm_model='gpt-3.5-turbo-1106', llm_model_path=None, multi_thread=True, num_clusters=5, pred_trigger='The answer is', random_seed=192, rationale_dir=None, save_dir='./experiment', test=False, topN=1, train=True)
2024-02-05 15:36:35,095 - C:/Users/lbq/Documents/GitHub/Rule_Finetune/main.py[line:86] - INFO: args: Namespace(cot_trigger='Answer: Let\'s think step by step. First rationale then answer.If you use any prior knowledge or rule during the inference, write them briefly in "<Begin>xxx</End>" format. Only do this if you find them. Note that these rules should be true in general.', cot_trigger_type='default1', data_dir=None, dataset='CLUTRR', debug=True, demo_save_dir='demosave', direct_answer_trigger_for_zeroshot_cot='The answer is', encoder='all-MiniLM-L6-v2', epoch=5, eval=False, llm_model='gpt-3.5-turbo-1106', llm_model_path=None, multi_thread=True, num_clusters=5, pred_trigger='The answer is', random_seed=192, rationale_dir=None, save_dir='./experiment', test=False, topN=1, train=True)
2024-02-05 15:40:30,882 - C:\Users\lbq\Documents\GitHub\Rule_Finetune\RuleFinetune\RuleTrainer.py[line:42] - INFO: 完成cold start
2024-02-05 15:45:51,875 - C:\Users\lbq\Documents\GitHub\Rule_Finetune\RuleFinetune\RuleTrainer.py[line:158] - INFO: epoch0的平均score为：0.675488774828951
2024-02-05 15:49:24,616 - C:\Users\lbq\Documents\GitHub\Rule_Finetune\RuleFinetune\RuleTrainer.py[line:158] - INFO: epoch1的平均score为：0.6874385014669373
2024-02-05 15:54:25,279 - C:\Users\lbq\Documents\GitHub\Rule_Finetune\RuleFinetune\RuleTrainer.py[line:158] - INFO: epoch2的平均score为：0.7079121038451185
2024-02-05 16:00:21,802 - C:\Users\lbq\Documents\GitHub\Rule_Finetune\RuleFinetune\RuleTrainer.py[line:158] - INFO: epoch3的平均score为：0.7086648799673606
2024-02-05 16:06:18,160 - C:\Users\lbq\Documents\GitHub\Rule_Finetune\RuleFinetune\RuleTrainer.py[line:158] - INFO: epoch4的平均score为：0.7248287647312037
2024-02-05 18:04:36,200 - C:/Users/lbq/Documents/GitHub/Rule_Finetune/main.py[line:86] - INFO: args: Namespace(cot_trigger='Answer: Let\'s think step by step. First rationale then answer.If you use any prior knowledge or rule during the inference, write them briefly in "<Begin>xxx</End>" format. Only do this if you find them. Note that these rules should be true in general.', cot_trigger_type='default1', data_dir=None, dataset='CLUTRR', debug=True, demo_save_dir='demosave', direct_answer_trigger_for_zeroshot_cot='The answer is', encoder='all-MiniLM-L6-v2', epoch=5, eval=False, llm_model='gpt-3.5-turbo-1106', llm_model_path=None, multi_thread=True, num_clusters=5, pred_trigger='The answer is', random_seed=192, rationale_dir=None, save_dir='./experiment', test=False, topN=1, train=True)
2024-02-05 18:05:05,925 - C:/Users/lbq/Documents/GitHub/Rule_Finetune/main.py[line:86] - INFO: args: Namespace(cot_trigger='Answer: Let\'s think step by step. First rationale then answer.If you use any prior knowledge or rule during the inference, write them briefly in "<Begin>xxx</End>" format. Only do this if you find them. Note that these rules should be true in general.', cot_trigger_type='default1', data_dir=None, dataset='CLUTRR', debug=True, demo_save_dir='demosave', direct_answer_trigger_for_zeroshot_cot='The answer is', encoder='all-MiniLM-L6-v2', epoch=5, eval=False, llm_model='gpt-3.5-turbo-1106', llm_model_path=None, multi_thread=True, num_clusters=5, pred_trigger='The answer is', random_seed=192, rationale_dir=None, save_dir='./experiment', test=False, topN=1, train=True)
2024-02-05 18:05:45,751 - C:/Users/lbq/Documents/GitHub/Rule_Finetune/main.py[line:86] - INFO: args: Namespace(cot_trigger='Answer: Let\'s think step by step. First rationale then answer.If you use any prior knowledge or rule during the inference, write them briefly in "<Begin>xxx</End>" format. Only do this if you find them. Note that these rules should be true in general.', cot_trigger_type='default1', data_dir=None, dataset='CLUTRR', debug=True, demo_save_dir='demosave', direct_answer_trigger_for_zeroshot_cot='The answer is', encoder='all-MiniLM-L6-v2', epoch=5, eval=False, llm_model='gpt-3.5-turbo-1106', llm_model_path=None, multi_thread=True, num_clusters=5, pred_trigger='The answer is', random_seed=192, rationale_dir=None, save_dir='./experiment', test=False, topN=1, train=True)
2024-02-05 18:08:40,682 - C:/Users/lbq/Documents/GitHub/Rule_Finetune/main.py[line:86] - INFO: args: Namespace(cot_trigger='Answer: Let\'s think step by step. First rationale then answer.If you use any prior knowledge or rule during the inference, write them briefly in "<Begin>xxx</End>" format. Only do this if you find them. Note that these rules should be true in general.', cot_trigger_type='default1', data_dir=None, dataset='CLUTRR', debug=True, demo_save_dir='demosave', direct_answer_trigger_for_zeroshot_cot='The answer is', encoder='all-MiniLM-L6-v2', epoch=5, eval=False, llm_model='gpt-3.5-turbo-1106', llm_model_path=None, multi_thread=True, num_clusters=5, pred_trigger='The answer is', random_seed=192, rationale_dir=None, save_dir='./experiment', test=False, topN=1, train=True)
2024-02-05 18:08:44,579 - C:\Users\lbq\Documents\GitHub\Rule_Finetune\RuleFinetune\RuleTrainer.py[line:42] - INFO: 完成cold start
2024-02-05 18:13:03,012 - C:\Users\lbq\Documents\GitHub\Rule_Finetune\RuleFinetune\RuleTrainer.py[line:158] - INFO: epoch0的平均score为：0.6979634240547944
2024-02-05 18:19:04,025 - C:\Users\lbq\Documents\GitHub\Rule_Finetune\RuleFinetune\RuleTrainer.py[line:158] - INFO: epoch1的平均score为：0.6990788571985148
2024-02-05 18:23:16,257 - C:\Users\lbq\Documents\GitHub\Rule_Finetune\RuleFinetune\RuleTrainer.py[line:158] - INFO: epoch2的平均score为：0.6921861144473502
2024-02-05 18:28:49,596 - C:\Users\lbq\Documents\GitHub\Rule_Finetune\RuleFinetune\RuleTrainer.py[line:158] - INFO: epoch3的平均score为：0.6931274424808908
2024-02-05 18:32:35,664 - C:\Users\lbq\Documents\GitHub\Rule_Finetune\RuleFinetune\RuleTrainer.py[line:158] - INFO: epoch4的平均score为：0.6818788886343599
2024-02-05 18:50:17,665 - C:/Users/lbq/Documents/GitHub/Rule_Finetune/main.py[line:86] - INFO: args: Namespace(cot_trigger='Answer: Let\'s think step by step. First rationale then answer.If you use any prior knowledge or rule during the inference, write them briefly in "<Begin>xxx</End>" format. Only do this if you find them. Note that these rules should be true in general.', cot_trigger_type='default1', data_dir=None, dataset='CLUTRR', debug=True, demo_save_dir='demosave', direct_answer_trigger_for_zeroshot_cot='The answer is', encoder='all-MiniLM-L6-v2', epoch=5, eval=False, llm_model='gpt-3.5-turbo-1106', llm_model_path=None, multi_thread=True, num_clusters=5, pred_trigger='The answer is', random_seed=192, rationale_dir=None, save_dir='./experiment', test=False, topN=1, train=True)
2024-02-05 18:50:25,713 - C:\Users\lbq\Documents\GitHub\Rule_Finetune\RuleFinetune\RuleTrainer.py[line:42] - INFO: 完成cold start
2024-02-05 18:53:39,884 - C:\Users\lbq\Documents\GitHub\Rule_Finetune\RuleFinetune\RuleTrainer.py[line:158] - INFO: epoch0的平均score为：0.7103225707766366
2024-02-05 19:11:06,983 - C:/Users/lbq/Documents/GitHub/Rule_Finetune/main.py[line:86] - INFO: args: Namespace(cot_trigger='Answer: Let\'s think step by step. First rationale then answer.If you use any prior knowledge or rule during the inference, write them briefly in "<Begin>xxx</End>" format. Only do this if you find them. Note that these rules should be true in general.', cot_trigger_type='default1', data_dir=None, dataset='CLUTRR', debug=True, demo_save_dir='demosave', direct_answer_trigger_for_zeroshot_cot='The answer is', encoder='all-MiniLM-L6-v2', epoch=5, eval=False, llm_model='gpt-3.5-turbo-1106', llm_model_path=None, multi_thread=True, num_clusters=5, pred_trigger='The answer is', random_seed=192, rationale_dir=None, save_dir='./experiment', test=False, topN=1, train=True)
2024-02-05 19:11:15,244 - C:\Users\lbq\Documents\GitHub\Rule_Finetune\RuleFinetune\RuleTrainer.py[line:42] - INFO: 完成cold start
2024-02-05 19:15:56,050 - C:\Users\lbq\Documents\GitHub\Rule_Finetune\RuleFinetune\RuleTrainer.py[line:158] - INFO: epoch0的平均score为：0.6986788884946508
2024-02-05 19:19:12,200 - C:\Users\lbq\Documents\GitHub\Rule_Finetune\RuleFinetune\RuleTrainer.py[line:158] - INFO: epoch1的平均score为：0.6930714851650813
2024-02-05 19:23:26,295 - C:\Users\lbq\Documents\GitHub\Rule_Finetune\RuleFinetune\RuleTrainer.py[line:158] - INFO: epoch2的平均score为：0.682766223173778
2024-02-05 19:27:38,226 - C:\Users\lbq\Documents\GitHub\Rule_Finetune\RuleFinetune\RuleTrainer.py[line:158] - INFO: epoch3的平均score为：0.6896499502521775
2024-02-05 19:31:56,536 - C:\Users\lbq\Documents\GitHub\Rule_Finetune\RuleFinetune\RuleTrainer.py[line:158] - INFO: epoch4的平均score为：0.6765532657786878
2024-02-05 21:18:52,807 - C:/Users/lbq/Documents/GitHub/Rule_Finetune/main.py[line:86] - INFO: args: Namespace(cot_trigger='Answer: Let\'s think step by step. First rationale then answer.If you use any prior knowledge or rule during the inference, write them briefly in "<Begin>xxx</End>" format. Only do this if you find them. Note that these rules should be true in general.', cot_trigger_type='default1', data_dir=None, dataset='CLUTRR', debug=True, demo_save_dir='demosave', direct_answer_trigger_for_zeroshot_cot='The answer is', encoder='all-MiniLM-L6-v2', epoch=5, eval=False, llm_model='gpt-3.5-turbo-1106', llm_model_path=None, multi_thread=True, num_clusters=5, pred_trigger='The answer is', random_seed=192, rationale_dir=None, save_dir='./experiment', test=False, topN=1, train=True)
2024-02-05 21:19:20,098 - C:/Users/lbq/Documents/GitHub/Rule_Finetune/main.py[line:86] - INFO: args: Namespace(cot_trigger='Answer: Let\'s think step by step. First rationale then answer.If you use any prior knowledge or rule during the inference, write them briefly in "<Begin>xxx</End>" format. Only do this if you find them. Note that these rules should be true in general.', cot_trigger_type='default1', data_dir=None, dataset='CLUTRR', debug=True, demo_save_dir='demosave', direct_answer_trigger_for_zeroshot_cot='The answer is', encoder='all-MiniLM-L6-v2', epoch=5, eval=False, llm_model='gpt-3.5-turbo-1106', llm_model_path=None, multi_thread=True, num_clusters=5, pred_trigger='The answer is', random_seed=192, rationale_dir=None, save_dir='./experiment', test=False, topN=1, train=True)
2024-02-05 21:27:20,583 - C:/Users/lbq/Documents/GitHub/Rule_Finetune/main.py[line:86] - INFO: args: Namespace(cot_trigger='Answer: Let\'s think step by step. First rationale then answer.If you use any prior knowledge or rule during the inference, write them briefly in "<Begin>xxx</End>" format. Only do this if you find them. Note that these rules should be true in general.', cot_trigger_type='default1', data_dir=None, dataset='CLUTRR', debug=True, demo_save_dir='demosave', direct_answer_trigger_for_zeroshot_cot='The answer is', encoder='all-MiniLM-L6-v2', epoch=5, eval=False, llm_model='gpt-3.5-turbo-1106', llm_model_path=None, multi_thread=True, num_clusters=5, pred_trigger='The answer is', random_seed=192, rationale_dir=None, save_dir='./experiment', test=False, topN=1, train=True)
2024-02-05 21:30:59,419 - C:/Users/lbq/Documents/GitHub/Rule_Finetune/main.py[line:86] - INFO: args: Namespace(cot_trigger='Answer: Let\'s think step by step. First rationale then answer.If you use any prior knowledge or rule during the inference, write them briefly in "<Begin>xxx</End>" format. Only do this if you find them. Note that these rules should be true in general.', cot_trigger_type='default1', data_dir=None, dataset='CLUTRR', debug=True, demo_save_dir='demosave', direct_answer_trigger_for_zeroshot_cot='The answer is', encoder='all-MiniLM-L6-v2', epoch=5, eval=False, llm_model='gpt-3.5-turbo-1106', llm_model_path=None, multi_thread=True, num_clusters=5, pred_trigger='The answer is', random_seed=192, rationale_dir=None, save_dir='./experiment', test=False, topN=1, train=True)
2024-02-05 21:45:56,775 - C:/Users/lbq/Documents/GitHub/Rule_Finetune/main.py[line:86] - INFO: args: Namespace(cot_trigger='Answer: Let\'s think step by step. First rationale then answer.If you use any prior knowledge or rule during the inference, write them briefly in "<Begin>xxx</End>" format. Only do this if you find them. Note that these rules should be true in general.', cot_trigger_type='default1', data_dir=None, dataset='CLUTRR', debug=True, demo_save_dir='demosave', direct_answer_trigger_for_zeroshot_cot='The answer is', encoder='all-MiniLM-L6-v2', epoch=5, eval=False, llm_model='gpt-3.5-turbo-1106', llm_model_path=None, multi_thread=True, num_clusters=5, pred_trigger='The answer is', random_seed=192, rationale_dir=None, save_dir='./experiment', test=False, topN=1, train=True)
2024-02-05 21:49:41,198 - C:/Users/lbq/Documents/GitHub/Rule_Finetune/main.py[line:86] - INFO: args: Namespace(cot_trigger='Answer: Let\'s think step by step. First rationale then answer.If you use any prior knowledge or rule during the inference, write them briefly in "<Begin>xxx</End>" format. Only do this if you find them. Note that these rules should be true in general.', cot_trigger_type='default1', data_dir=None, dataset='CLUTRR', debug=True, demo_save_dir='demosave', direct_answer_trigger_for_zeroshot_cot='The answer is', encoder='all-MiniLM-L6-v2', epoch=5, eval=False, llm_model='gpt-3.5-turbo-1106', llm_model_path=None, multi_thread=True, num_clusters=5, pred_trigger='The answer is', random_seed=192, rationale_dir=None, save_dir='./experiment', test=False, topN=1, train=True)
2024-02-05 21:50:00,611 - C:/Users/lbq/Documents/GitHub/Rule_Finetune/main.py[line:86] - INFO: args: Namespace(cot_trigger='Answer: Let\'s think step by step. First rationale then answer.If you use any prior knowledge or rule during the inference, write them briefly in "<Begin>xxx</End>" format. Only do this if you find them. Note that these rules should be true in general.', cot_trigger_type='default1', data_dir=None, dataset='CLUTRR', debug=True, demo_save_dir='demosave', direct_answer_trigger_for_zeroshot_cot='The answer is', encoder='all-MiniLM-L6-v2', epoch=5, eval=False, llm_model='gpt-3.5-turbo-1106', llm_model_path=None, multi_thread=True, num_clusters=5, pred_trigger='The answer is', random_seed=192, rationale_dir=None, save_dir='./experiment', test=False, topN=1, train=True)
