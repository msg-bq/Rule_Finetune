2024-02-04 17:53:49,616 - C:/Users/lbq/Documents/GitHub/Rule_Finetune/main.py[line:85] - INFO: args: Namespace(cot_trigger='Answer: Let\'s think step by step. First rationale then answer.If you use any prior knowledge or rule during the inference, write them briefly in "<Begin>xxx</End>" format. Only do this if you find them. Note that these rules should be true in general.', cot_trigger_type='default1', data_dir=None, dataset='CLUTRR', debug=True, demo_save_dir='demosave', direct_answer_trigger_for_zeroshot_cot='The answer is', encoder='all-MiniLM-L6-v2', epoch=10, eval=False, llm_model='gpt-3.5-turbo-1106', llm_model_path=None, multi_thread=True, num_clusters=5, pred_trigger='The answer is', random_seed=192, rationale_dir=None, save_dir='./experiment', test=False, topN=1, train=True)
2024-02-04 17:54:14,649 - C:/Users/lbq/Documents/GitHub/Rule_Finetune/main.py[line:85] - INFO: args: Namespace(cot_trigger='Answer: Let\'s think step by step. First rationale then answer.If you use any prior knowledge or rule during the inference, write them briefly in "<Begin>xxx</End>" format. Only do this if you find them. Note that these rules should be true in general.', cot_trigger_type='default1', data_dir=None, dataset='CLUTRR', debug=True, demo_save_dir='demosave', direct_answer_trigger_for_zeroshot_cot='The answer is', encoder='all-MiniLM-L6-v2', epoch=10, eval=False, llm_model='gpt-3.5-turbo-1106', llm_model_path=None, multi_thread=True, num_clusters=5, pred_trigger='The answer is', random_seed=192, rationale_dir=None, save_dir='./experiment', test=False, topN=1, train=True)
2024-02-04 17:54:14,685 - C:\Users\lbq\Documents\GitHub\Rule_Finetune\RuleFinetune\RuleTrainer.py[line:42] - INFO: 完成cold start
2024-02-04 17:55:37,250 - C:\Users\lbq\Documents\GitHub\Rule_Finetune\RuleFinetune\RuleTrainer.py[line:158] - INFO: epoch0的平均score为：0.6024444231891043
2024-02-04 17:57:24,188 - C:\Users\lbq\Documents\GitHub\Rule_Finetune\RuleFinetune\RuleTrainer.py[line:158] - INFO: epoch1的平均score为：0.6945238365970077
2024-02-04 17:59:07,669 - C:\Users\lbq\Documents\GitHub\Rule_Finetune\RuleFinetune\RuleTrainer.py[line:158] - INFO: epoch2的平均score为：0.7159410862769072
2024-02-04 18:00:41,819 - C:\Users\lbq\Documents\GitHub\Rule_Finetune\RuleFinetune\RuleTrainer.py[line:158] - INFO: epoch3的平均score为：0.7028720579140747
